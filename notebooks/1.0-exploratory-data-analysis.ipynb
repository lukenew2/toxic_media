{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10932aa5",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis \n",
    "---\n",
    "*Disclaimer: This notebook contains text that is profound, vulgar, and offensive due to the nature of the dataset.*\n",
    "\n",
    "We live in an age where people's lives have become intertwined with their online presence allowing humans to engage with one another on a larger scale than ever before.  However, not all of these interactions foster growth.  People exploit the fact that their identity remains hidden and choose to target one another with unwarranted abuse causing harm instead of growth.  For our society to truly prosper from the digital age we have to combat this toxic behavior.  This will enable more and more people who are scared of what other people will think when they post on social media to engage freely without the fear of being the target of online hate.  \n",
    "\n",
    "Our task is to improve civility on social media platforms (e.g., Twitter) and online comment forums (e.g., Reddit) by training a model that determines how likely a users comment will make another user leave a conversation.  With our model, we will create a web application that tracks how toxic each social media platform and online comment forum is to bring awareness to this issue and spark initiative to create a toxic free environment for all users.  \n",
    "\n",
    "This issue can only be solved with the help of everyone by encouraging kindness instead of spreading hate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb820bb",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "The dataset used in this project is from the kaggle competition: [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data).\n",
    "\n",
    "In 2017 the Civil Comments platform shutdown and released their archive of ~2 million public comments for researchers to study in an effort to improve civility online. Jigsaw funded the annotation of this data by human raters. \n",
    "\n",
    "The column `toxicity` is our toxicity label which contains a number between 0-1 denoting the fraction of human labelers that believed the comment would make someone else leave a conversation. \n",
    "\n",
    "For our analysis we'll define the comment as toxic (denoted 1) when the value of our target `toxicity` is greater than or equal to 0.5 otherwise we'll assign the instance to the negative class (denoted 0).\n",
    "\n",
    "There are a lot of additional labels denoting the fraction of human labelers who believed the comment depicted several other sub-toxic labels and whether specific identity groups were mentioned in the comment. These columns will be **removed** from our analysis because we will not have access to this data in the production environment.\n",
    "\n",
    "### Labeling Schema\n",
    "As mentioned on Kaggle, each comment was shown to up to 10 human labelers.  The labelers were asked to rate how toxic each comment is. \n",
    "* Very Toxic\n",
    "* Toxic\n",
    "* Hard to Say\n",
    "* Not Toxic\n",
    "\n",
    "The ratings were then aggragated into the `target` column.\n",
    "\n",
    "*Note: Some comments were shown to more than 10 human labelers because of sampling strategies to increase rating accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44666c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import textblob\n",
    "import wordcloud\n",
    "\n",
    "# Root directory used to navigate tree.\n",
    "PROJECT_ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Path to save images and figures.\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"reports/figures\")\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "    \n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    \"\"\"\n",
    "    Saves figures in toxic_media/reports/figures.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_id : str\n",
    "        Name of the figure to be saved.\n",
    "    tight_layout : bool, default=True\n",
    "        Enables padding between figure edge and edges of subplots when set to True.\n",
    "    fig_extension : {'jpg', 'png', 'svg'}, default='png'\n",
    "        Figure format.\n",
    "    resolution : int\n",
    "        Figure resolution.\n",
    "    \"\"\"\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(f\"Saving figure: {fig_id}\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ebaf8",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "We're going to start by loading the raw data to get a quick look at it before creating a training set with which we'll use to explore in-depth. As mentioned above, the initial data file has extra columns we will not be using.  Therefore, we'll only load in the target column and the comment text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8a5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(PROJECT_ROOT_DIR, \"data\")\n",
    "\n",
    "def load_data(path=\"raw/all_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load data into pandas dataframe object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str, default=raw/all_data.csv\n",
    "        Directory and filename in format 'directory/filename.csv'.\n",
    "    \"\"\"\n",
    "    csv_path = os.path.join(DATA_DIR, path)\n",
    "    \n",
    "    return pd.read_csv(csv_path, usecols=['comment_text', 'toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c50651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c94e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He got his money... now he lies in wait till a...</td>\n",
       "      <td>0.373134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mad dog will surely put the liberals in mental...</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxicity\n",
       "0  He got his money... now he lies in wait till a...  0.373134\n",
       "1  Mad dog will surely put the liberals in mental...  0.605263\n",
       "2  And Trump continues his lifelong cowardice by ...  0.666667\n",
       "3  \"while arresting a man for resisting arrest\".\\...  0.815789\n",
       "4     Tucker and Paul are both total bad ass mofo's.  0.550000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4309c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1999516 entries, 0 to 1999515\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   comment_text  object \n",
      " 1   toxicity      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 30.5+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f0724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    5.001210e-07\n",
       "toxicity        0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.isnull().sum() / len(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda72c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.999516e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.029241e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.970386e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           toxicity\n",
       "count  1.999516e+06\n",
       "mean   1.029241e-01\n",
       "std    1.970386e-01\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    1.666667e-01\n",
       "max    1.000000e+00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdba5ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d1647f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.941048\n",
       "1.0    0.058952\n",
       "Name: toxicity, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic[\"toxicity\"].round().value_counts() / len(toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2231d31",
   "metadata": {},
   "source": [
    "### Summary\n",
    "After our initial look into the data we found a few things to take note of:\n",
    "* We're missing text in a few instances (handle this in preprocessing).\n",
    "* Our target column `toxicity` is heavily skewed towards 0 meaning we'll have to deal with a class imbalance when it comes to modeling (~5% of comments are toxic).\n",
    "* There is a good amount of instances labeled around 0.5 that might be hard to predict.  It seems labelers were not in agreement whether these comments were toxic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6c441",
   "metadata": {},
   "source": [
    "## Test Set\n",
    "Before we dive deep into the dataset we need to create a test set.  Our test set will be 5% (~100,000 instances) which is plenty big enough to provide accurate statistics in our modeling phase. Since we plan on building deep learning models which benefit greatly from large amounts of data this will allow us to allocate 95% of our dataset for training.  \n",
    "\n",
    "Since our dataset is imbalanced we will use stratified sampling to preserve the ratio of classes in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b3861cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = toxic['comment_text']\n",
    "y = toxic['toxicity'].round()\n",
    "\n",
    "def create_test(X, y, test_size=0.05):\n",
    "    \"\"\"\n",
    "    Create holdout data with stratified sampling techniques.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Raw feature set to be split into training and test set.\n",
    "    test_size : float, default=0.05\n",
    "        Decimal value representing percentage of dataset used to create holdout set.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    This function only creates the test set if it has not been created yet.  \n",
    "    \"\"\"\n",
    "    # Check if test set exists.\n",
    "    TEST_PATH = os.path.join(DATA_DIR, \"interim/test.csv\")\n",
    "    if not os.path.exists(TEST_PATH):\n",
    "        \n",
    "        # Train test split with stratified sampling of the target.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                            stratify=y)\n",
    "        \n",
    "        # Combine target and text into train and test sets.\n",
    "        train = pd.concat([X_train, y_train], axis=1)\n",
    "        test = pd.concat([X_test, y_test], axis=1)\n",
    "        \n",
    "        # Save train and test set in directory /data/interim\n",
    "        path = os.path.join(DATA_DIR, \"interim\")\n",
    "        train.to_csv(os.path.join(path, \"train.csv\"), index=False)\n",
    "        test.to_csv(os.path.join(path, \"test.csv\"), index=False)\n",
    "\n",
    "create_test(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c034a3",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70dd74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = load_data(path=\"interim/train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic",
   "language": "python",
   "name": "toxic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
